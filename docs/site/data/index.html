<!-- Elements added to main will be displayed on all pages -->

<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.2, mkdocs-material-7.2.4">
    
    
      
        <title>Data radtorch.data - RADTorch</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.f7f47774.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.3f5d1f46.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
      <link rel="stylesheet" href="https://unpkg.com/mermaid@8.8.0/dist/mermaid.css">
    
    
      


    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="cyan" data-md-color-accent="cyan">
  
    
    <script>function __prefix(e){return new URL("..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
      <script>var palette=__get("__palette");if(null!==palette&&"object"==typeof palette.color)for(var key in palette.color)document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#data-radtorchdata" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="RADTorch" class="md-header__button md-logo" aria-label="RADTorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 22v-2h3v-3h2v3.5c0 .39-.16.74-.46 1.04-.3.3-.65.46-1.04.46H17M7 22H3.5c-.39 0-.74-.16-1.04-.46-.3-.3-.46-.65-.46-1.04V17h2v3h3v2M17 2h3.5c.39 0 .74.16 1.04.46.3.3.46.65.46 1.04V7h-2V4h-3V2M7 2v2H4v3H2V3.5c0-.39.16-.74.46-1.04.3-.3.65-.46 1.04-.46H7m6 15.25 4-2.3v-4.59l-4 2.3v4.59m-1-6.33 4-2.29-4-2.35-4 2.35 4 2.29m-5 4.03 4 2.3v-4.59l-4-2.3v4.59m11.23-7.36c.5.32.77.75.77 1.32v6.32c0 .57-.27 1-.77 1.32l-5.48 3.18c-.5.32-1 .32-1.5 0l-5.48-3.18c-.5-.32-.77-.75-.77-1.32V8.91c0-.57.27-1 .77-1.32l5.48-3.18c.25-.13.5-.19.75-.19s.5.06.75.19l5.48 3.18z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <!-- <span class="md-ellipsis"> -->
          <!-- <a href=".." title="RADTorch" class="md-header__button md-logo" aria-label="RADTorch" data-md-component="logo"> -->
            RADTorch
          <!-- </a> -->

          <!-- </span> -->
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Data <small>radtorch.data</small>
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="cyan" data-md-color-accent="cyan"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M7 10a2 2 0 0 1 2 2 2 2 0 0 1-2 2 2 2 0 0 1-2-2 2 2 0 0 1 2-2m10-3a5 5 0 0 1 5 5 5 5 0 0 1-5 5H7a5 5 0 0 1-5-5 5 5 0 0 1 5-5h10M7 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3h10a3 3 0 0 0 3-3 3 3 0 0 0-3-3H7z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="cyan" data-md-color-accent="cyan"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/radtorch/radtorch" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    radtorch/radtorch
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href=".." class="md-tabs__link">
      RADTorch
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../about/" class="md-tabs__link">
      About
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../start/" class="md-tabs__link">
      Getting Started
    </a>
  </li>

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="./" class="md-tabs__link md-tabs__link--active">
        Documentation
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../version/" class="md-tabs__link">
        Information
      </a>
    </li>
  

      
        
  
  


  <li class="md-tabs__item">
    <a href="../support/" class="md-tabs__link">
      Help
    </a>
  </li>

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="RADTorch" class="md-nav__button md-logo" aria-label="RADTorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 22v-2h3v-3h2v3.5c0 .39-.16.74-.46 1.04-.3.3-.65.46-1.04.46H17M7 22H3.5c-.39 0-.74-.16-1.04-.46-.3-.3-.46-.65-.46-1.04V17h2v3h3v2M17 2h3.5c.39 0 .74.16 1.04.46.3.3.46.65.46 1.04V7h-2V4h-3V2M7 2v2H4v3H2V3.5c0-.39.16-.74.46-1.04.3-.3.65-.46 1.04-.46H7m6 15.25 4-2.3v-4.59l-4 2.3v4.59m-1-6.33 4-2.29-4-2.35-4 2.35 4 2.29m-5 4.03 4 2.3v-4.59l-4-2.3v4.59m11.23-7.36c.5.32.77.75.77 1.32v6.32c0 .57-.27 1-.77 1.32l-5.48 3.18c-.5.32-1 .32-1.5 0l-5.48-3.18c-.5-.32-.77-.75-.77-1.32V8.91c0-.57.27-1 .77-1.32l5.48-3.18c.25-.13.5-.19.75-.19s.5.06.75.19l5.48 3.18z"/></svg>

    </a>
    RADTorch
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/radtorch/radtorch" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    radtorch/radtorch
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        RADTorch
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../about/" class="md-nav__link">
        About
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../start/" class="md-nav__link">
        Getting Started
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      <label class="md-nav__link" for="__nav_4">
        Documentation
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Documentation" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Documentation
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Data <small>radtorch.data</small>
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Data <small>radtorch.data</small>
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#radtorch.data.ImageObject" class="md-nav__link">
    ImageObject
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#radtorch.data.VolumeObject" class="md-nav__link">
    VolumeObject
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#radtorch.data.ImageDataset" class="md-nav__link">
    ImageDataset
  </a>
  
    <nav class="md-nav" aria-label="ImageDataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#radtorch.data.ImageDataset-methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav" aria-label="Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#radtorch.data.ImageDataset.data_stat" class="md-nav__link">
    data_stat()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#radtorch.data.ImageDataset.view_batch" class="md-nav__link">
    view_batch()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#radtorch.data.ImageDataset.view_image" class="md-nav__link">
    view_image()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#radtorch.data.VolumeDataset" class="md-nav__link">
    VolumeDataset
  </a>
  
    <nav class="md-nav" aria-label="VolumeDataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#radtorch.data.VolumeDataset-methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav" aria-label="Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#radtorch.data.VolumeDataset.data_stat" class="md-nav__link">
    data_stat()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#radtorch.data.VolumeDataset.view_study" class="md-nav__link">
    view_study()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../model/" class="md-nav__link">
        Model <small>radtorch.model</small>
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../classifier/" class="md-nav__link">
        Classifier <small>radtorch.classifier</small>
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../extractor/" class="md-nav__link">
        Feature Extractor <small>radtorch.extractor</small>
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../inference/" class="md-nav__link">
        Inference <small>radtorch.inference</small>
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../metrics/" class="md-nav__link">
        Metrics <small>radtorch.metrics</small>
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      <label class="md-nav__link" for="__nav_5">
        Information
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Information" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Information
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../version/" class="md-nav__link">
        Version Log
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../copyrights/" class="md-nav__link">
        Copyrights
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../support/" class="md-nav__link">
        Help
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="data-radtorchdata">Data <small>radtorch.data</small></h1>
<p>One of the core functions of <code>radtorch</code> is the ability to handle different types of medical/non-medical DICOM/non-DICOM images efficiently with ease. Below is list of classes that make the magic happen.</p>


  <div class="doc doc-object doc-class">



<h2 id="radtorch.data.ImageObject" class="doc doc-heading">
        <code>
ImageObject        </code>



</h2>

    <div class="doc doc-contents first">

      <p>Creates a 3D tensor whose dimensions = [channels, width, height] from an image path.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>path</code></td>
        <td><code>str</code></td>
        <td><p>Path to an image.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>out_channels</code></td>
        <td><code>int</code></td>
        <td><p>Number of output channels. Only 1 and 3 channels supported.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>transforms</code></td>
        <td><code>list</code></td>
        <td><p>Albumentations transformations. See <a href="https://albumentations.ai/docs/getting_started/image_augmentation/">Image Augmentation</a>.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>WW</code></td>
        <td><code>int or list</code></td>
        <td><p>Window width for DICOM images. Single value if using 1 channel or list of 3 values for 3 channels. See <a href="https://radiopaedia.org/articles/windowing-ct">https://radiopaedia.org/articles/windowing-ct</a>.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>WL</code></td>
        <td><code>int or list</code></td>
        <td><p>Window level for DICOM images. Single value if using 1 channel or list of 3 values for 3 channels. See <a href="https://radiopaedia.org/articles/windowing-ct">https://radiopaedia.org/articles/windowing-ct</a>.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>tensor</code></td>
      <td><p>3D tensor whose dimensions = [channels, width, height]</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">i</span> <span class="o">=</span> <span class="n">radtorch</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ImageObject</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s1">&#39;data/PROTOTYPE/DIRECTORY/abdomen/abd_1/1-001.dcm&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span>

<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">])</span>
</code></pre></div>



    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="radtorch.data.VolumeObject" class="doc doc-heading">
        <code>
VolumeObject        </code>



</h2>

    <div class="doc doc-contents first">

      <p>Creates an Image Volume Object (4D tensor) from series images contained in a folder.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>directory</code></td>
        <td><code>str</code></td>
        <td><p>Folder containing series/sequence images. Images must be DICOM files.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>out_channels</code></td>
        <td><code>int</code></td>
        <td><p>Number of output channels. Only 1 and 3 channels supported.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>transforms</code></td>
        <td><code>list</code></td>
        <td><p>Albumentations transformations. See <a href="https://albumentations.ai/docs/getting_started/image_augmentation/">https://albumentations.ai/docs/getting_started/image_augmentation/</a>.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>WW</code></td>
        <td><code>int or list</code></td>
        <td><p>Window width for DICOM images. Single value if using 1 channel or list of 3 values for 3 channels. See <a href="https://radiopaedia.org/articles/windowing-ct">https://radiopaedia.org/articles/windowing-ct</a>.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>WL</code></td>
        <td><code>int or list</code></td>
        <td><p>Window level for DICOM images. Single value if using 1 channel or list of 3 values for 3 channels. See <a href="https://radiopaedia.org/articles/windowing-ct">https://radiopaedia.org/articles/windowing-ct</a>.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>tensor</code></td>
      <td><p>4D tensor with dimensions = [channels, number_images/depth, width, height]. See <a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html">https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html</a></p></td>
    </tr>
  </tbody>
</table>
<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">i</span> <span class="o">=</span> <span class="n">radtorch</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">VolumeObject</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="s1">&#39;data/PROTOTYPE/DIRECTORY/abdomen/abd_1&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span>

<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">])</span>
</code></pre></div>



    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="radtorch.data.ImageDataset" class="doc doc-heading">
        <code>
ImageDataset            (<span title="torch.utils.data.dataset.Dataset">Dataset</span>)
        </code>



</h2>

    <div class="doc doc-contents first">

      <p>Creates pytorch dataset(s) and dataloader(s) objects from a parent folder. Use this class for image tasks that invovles handling each single image as a single instance of your dataset.</p>

<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">radtorch</span>
<span class="kn">import</span> <span class="nn">albumentations</span> <span class="k">as</span> <span class="nn">A</span>

<span class="c1"># Specify image transformations</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">A</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">)])</span>

<span class="c1"># Create dataset object</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">radtorch</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ImageDataset</span><span class="p">(</span>
                                <span class="n">folder</span><span class="o">=</span><span class="s1">&#39;data/4CLASS/&#39;</span><span class="p">,</span>
                                <span class="n">split</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;valid&#39;</span><span class="p">:</span><span class="mf">0.2</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span><span class="mf">0.2</span><span class="p">},</span>
                                <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">transforms</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span><span class="n">T</span><span class="p">,</span><span class="s1">&#39;valid&#39;</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span><span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="n">T</span><span class="p">},</span>
                                 <span class="p">)</span>

<span class="n">ds</span><span class="o">.</span><span class="n">data_stat</span><span class="p">()</span>
</code></pre></div>
<div style="text-align:center"><img src="../assets/5.png" style="width:50%; height:50%" /></div>

<div class="highlight"><pre><span></span><code><span class="n">ds</span><span class="o">.</span><span class="n">table</span>
</code></pre></div>
<div style="text-align:center"><img src="../assets/6.png" style="width:50%; height:50%" /></div>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>folder</code></td>
        <td><code>str</code></td>
        <td><p>Parent folder containing images. <code>radtorch.ImageDataset</code> expects images to be arranged in the following structure:
<div class="highlight"><pre><span></span><code>root/
    class_1/
            image_1
            image_2
            ...
    class_2/
            image_1
            image_2
            ...
</code></pre></div></p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>name</code></td>
        <td><code>str</code></td>
        <td><p>Name to be give to the dataset. If none provided, the current date and time will be used to created a generic dataset name. (default=None)</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>label_table</code></td>
        <td><code>str|dataframe</code></td>
        <td><p>The table containing data labels for your images. Expected table should contain at least 2 columns: image path column and a label column. Table can be string path to CSV or a pandas dataframe object.(default=None)</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>instance_id</code></td>
        <td><code>bool</code></td>
        <td><p>True if the data provided in the image path column in label_table contains the image id not the absolute path for the image. (default= False)</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>add_extension</code></td>
        <td><code>bool</code></td>
        <td><p>If instance_id =True, use this to add extension to image path as needed. Extension must be provided without "." e.g. "dcm". (default=False)</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>out_channels</code></td>
        <td><code>int</code></td>
        <td><p>Number of output channels. (default=1)</p></td>
        <td><code>1</code></td>
      </tr>
      <tr>
        <td><code>WW</code></td>
        <td><code>int or list</code></td>
        <td><p>Window width for DICOM images. Single value if using 1 channel or list of 3 values for 3 channels. See <a href="https://radiopaedia.org/articles/windowing-ct">https://radiopaedia.org/articles/windowing-ct</a>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>WL</code></td>
        <td><code>int or list</code></td>
        <td><p>Window level for DICOM images. Single value if using 1 channel or list of 3 values for 3 channels. See <a href="https://radiopaedia.org/articles/windowing-ct">https://radiopaedia.org/articles/windowing-ct</a>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>path_col</code></td>
        <td><code>str</code></td>
        <td><p>Name of the column containing image path data in the label_table. (default='path')</p></td>
        <td><code>&#39;path&#39;</code></td>
      </tr>
      <tr>
        <td><code>label_col</code></td>
        <td><code>str</code></td>
        <td><p>Name of the column containing label data in the label_table. (default='label')</p></td>
        <td><code>&#39;label&#39;</code></td>
      </tr>
      <tr>
        <td><code>extension</code></td>
        <td><code>str</code></td>
        <td><p>Type/Extension of images. (default='dcm')</p></td>
        <td><code>&#39;dcm&#39;</code></td>
      </tr>
      <tr>
        <td><code>transforms</code></td>
        <td><code>dict</code></td>
        <td><p>Dictionary of Albumentations transformations in the form of {'train': .. , 'valid': .. , 'test': .. }. See https://albumentations.ai/docs/getting_started/image_augmentation/ . (default=None)</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>random_state</code></td>
        <td><code>int</code></td>
        <td><p>Random seed (default=100)</p></td>
        <td><code>100</code></td>
      </tr>
      <tr>
        <td><code>sample</code></td>
        <td><code>float</code></td>
        <td><p>Sample or percent of the overall data to be used. (default=1.0)</p></td>
        <td><code>1.0</code></td>
      </tr>
      <tr>
        <td><code>split</code></td>
        <td><code>dict</code></td>
        <td><p>dictionary defining how data will be split for training/validation/testing. Follows the sturcture {'valid': float, 'test': float} or {'valid':'float'} in case no testing subset is needed. The percent of the training subset is infered automatically.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>ignore_zero_img</code></td>
        <td><code>bool</code></td>
        <td><p>True to ignore images containig all zero pixels. (default=False)</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>normalize</code></td>
        <td><code>bool</code></td>
        <td><p>True to normalize image data between 0 and 1. (default=True)</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>batch_size</code></td>
        <td><code>int</code></td>
        <td><p>Dataloader batch size. (default = 16)</p></td>
        <td><code>16</code></td>
      </tr>
      <tr>
        <td><code>shuffle</code></td>
        <td><code>bool</code></td>
        <td><p>True to shuffle images during training. (default=True)</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>weighted_sampler</code></td>
        <td><code>bool</code></td>
        <td><p>True to use a weighted sampler for unbalanced datasets. See https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler. (default=False)</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>num_workers</code></td>
        <td><code>int</code></td>
        <td><p>Dataloader CPU workers. (default = 0)</p></td>
        <td><code>0</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Attributes:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>classes</code></td>
        <td><code>list</code></td>
        <td><p>List of generated classes/labels.</p></td>
      </tr>
      <tr>
        <td><code>class_to_idx</code></td>
        <td><code>dict</code></td>
        <td><p>Dictionary of generated classes/labels and corresponding class/label id.</p></td>
      </tr>
      <tr>
        <td><code>idx_train</code></td>
        <td><code>list</code></td>
        <td><p>List of index values of images/instances used for training subset. These refer to index of <code>ImageDataset.table</code>.</p></td>
      </tr>
      <tr>
        <td><code>idx_valid</code></td>
        <td><code>list</code></td>
        <td><p>List of index values of images/instances used for validation subset. These refer to index of <code>ImageDataset.table</code>.</p></td>
      </tr>
      <tr>
        <td><code>idx_test</code></td>
        <td><code>list</code></td>
        <td><p>List of index values of images/instances used for testing subset. These refer to index of <code>ImageDataset.table</code>.</p></td>
      </tr>
      <tr>
        <td><code>table</code></td>
        <td><code>pandas dataframe</code></td>
        <td><p>Table of images , paths and their labels.</p></td>
      </tr>
      <tr>
        <td><code>table_train</code></td>
        <td><code>pandas dataframe</code></td>
        <td><p>Table of images used for training. Subset of <code>ImageDataset.table</code>.</p></td>
      </tr>
      <tr>
        <td><code>table_valid</code></td>
        <td><code>pandas dataframe</code></td>
        <td><p>Table of images used for validation. Subset of <code>ImageDataset.table</code>.</p></td>
      </tr>
      <tr>
        <td><code>table_test</code></td>
        <td><code>pandas dataframe</code></td>
        <td><p>Table of images used for testing. Subset of <code>ImageDataset.table</code>.</p></td>
      </tr>
      <tr>
        <td><code>tables</code></td>
        <td><code>dict</code></td>
        <td><p>Dictionary of all generated tables in the form of: {'train': table, 'valid':table, 'test':table}.</p></td>
      </tr>
      <tr>
        <td><code>dataset_train</code></td>
        <td><code>pytorch dataset object</code></td>
        <td><p>Training <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset">pytorch Dataset</a></p></td>
      </tr>
      <tr>
        <td><code>dataset_valid</code></td>
        <td><code>pytorch dataset object</code></td>
        <td><p>Validation <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset">pytorch Dataset</a></p></td>
      </tr>
      <tr>
        <td><code>dataset_test</code></td>
        <td><code>pytorch dataset object</code></td>
        <td><p>Testing <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset">pytorch Dataset</a></p></td>
      </tr>
      <tr>
        <td><code>datasets</code></td>
        <td><code>dict</code></td>
        <td><p>Dictionary of all generated Datasets in the form of: {'train': Dataset, 'valid':Dataset, 'test':Dataset}.</p></td>
      </tr>
      <tr>
        <td><code>dataloader_train</code></td>
        <td><code>pytorch dataloader object</code></td>
        <td><p>Training <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">pytorch DataLoader</a></p></td>
      </tr>
      <tr>
        <td><code>dataloader_valid</code></td>
        <td><code>pytorch dataloader object</code></td>
        <td><p>Validation <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">pytorch DataLoader</a></p></td>
      </tr>
      <tr>
        <td><code>dataloader_test</code></td>
        <td><code>pytorch dataloader object</code></td>
        <td><p>Testing <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">pytorch DataLoader</a></p></td>
      </tr>
      <tr>
        <td><code>dataloaders</code></td>
        <td><code>dict</code></td>
        <td><p>Dictionary of all generated Dataloaders in the form of: {'train': Dataloader, 'valid':Dataloader, 'test':Dataloader}.</p></td>
      </tr>
      <tr>
        <td><code>class_weights</code></td>
        <td><code>tensor</code></td>
        <td><p>Values of class weights, for imbalanced datasets, to be used to weight loss functions. See <a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss">https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss</a>.</p></td>
      </tr>
      <tr>
        <td><code>sampler_weights</code></td>
        <td><code>tensor</code></td>
        <td><p>Values of vlass weights, for imbalanced datasets, to be used to sample from the dataset using Pytroch WeightedRandomSampler. Affects only training dataset not validation or testing. See <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler">https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler</a></p></td>
      </tr>
  </tbody>
</table>



  <div class="doc doc-children">







<h3 id="radtorch.data.ImageDataset-methods">Methods</h3>

  <div class="doc doc-object doc-method">



<h4 id="radtorch.data.ImageDataset.data_stat" class="doc doc-heading">
<code class="highlight language-python"><span class="n">data_stat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>Displays distribution of classes across subsets as table or plot.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>plot</code></td>
        <td><code>bool</code></td>
        <td><p>True, display data as figure. False, display data as table.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>figsize</code></td>
        <td><code>tuple</code></td>
        <td><p>size of the displayed figure.</p></td>
        <td><code>(8, 6)</code></td>
      </tr>
      <tr>
        <td><code>cmap</code></td>
        <td><code>string</code></td>
        <td><p>Name of Matplotlib color map to be used. See <a href="https://matplotlib.org/stable/tutorials/colors/colormaps.html">Matplotlib colormaps</a></p></td>
        <td><code>&#39;viridis&#39;</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>pandas dataframe</code></td>
      <td><p>if plot=False</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Examples:</strong></p>
    
      <div class="highlight"><pre><span></span><code><span class="n">ds</span> <span class="o">=</span> <span class="n">radtorch</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ImageDataset</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="s1">&#39;data/4CLASS/&#39;</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ds</span><span class="o">.</span><span class="n">data_stat</span><span class="p">()</span>
</code></pre></div>
<div style="text-align:center"><img src="../assets/1.png" style="width:50%; height:50%" /></div>

    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 id="radtorch.data.ImageDataset.view_batch" class="doc doc-heading">
<code class="highlight language-python"><span class="n">view_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rows</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>Displays a batch from a certain subset.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>subset</code></td>
        <td><code>string</code></td>
        <td><p>Datasubset to use: either 'train', 'valid', or 'test'.</p></td>
        <td><code>&#39;train&#39;</code></td>
      </tr>
      <tr>
        <td><code>figsize</code></td>
        <td><code>tuple</code></td>
        <td><p>Size of the displayed figure.</p></td>
        <td><code>(15, 5)</code></td>
      </tr>
      <tr>
        <td><code>cmap</code></td>
        <td><code>string</code></td>
        <td><p>Name of Matplotlib color map to be used. See <a href="https://matplotlib.org/stable/tutorials/colors/colormaps.html">Matplotlib colormaps</a></p></td>
        <td><code>&#39;gray&#39;</code></td>
      </tr>
      <tr>
        <td><code>num_images</code></td>
        <td><code>int</code></td>
        <td><p>Number of displayed image. Usually equals batch_size unless otherwise specified.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>rows</code></td>
        <td><code>int</code></td>
        <td><p>Number of rows.</p></td>
        <td><code>2</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>figure</code></td>
      <td><p>figure containing samples</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Examples:</strong></p>
    
      <div class="highlight"><pre><span></span><code><span class="n">ds</span> <span class="o">=</span> <span class="n">radtorch</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ImageDataset</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="s1">&#39;data/4CLASS/&#39;</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ds</span><span class="o">.</span><span class="n">view_batch</span><span class="p">()</span>
</code></pre></div>
<div style="text-align:center"><img src="../assets/2.png" style="width:80%; height:80%" /></div>

    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 id="radtorch.data.ImageDataset.view_image" class="doc doc-heading">
<code class="highlight language-python"><span class="n">view_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>Displays separate images/channels of an image.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>id</code></td>
        <td><code>int</code></td>
        <td><p>Target image id in <code>dataset.table</code> (row index).</p></td>
        <td><code>0</code></td>
      </tr>
      <tr>
        <td><code>figsize</code></td>
        <td><code>tuple</code></td>
        <td><p>size of the displayed figure.</p></td>
        <td><code>(25, 5)</code></td>
      </tr>
      <tr>
        <td><code>cmap</code></td>
        <td><code>string</code></td>
        <td><p>Name of Matplotlib color map to be used. See <a href="https://matplotlib.org/stable/tutorials/colors/colormaps.html">Matplotlib colormaps</a></p></td>
        <td><code>&#39;gray&#39;</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>figure</code></td>
      <td><p>figure containing samples</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Examples:</strong></p>
    
      <div class="highlight"><pre><span></span><code><span class="n">ds</span> <span class="o">=</span> <span class="n">radtorch</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ImageDataset</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="s1">&#39;data/4CLASS/&#39;</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ds</span><span class="o">.</span><span class="n">view_image</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
</code></pre></div>
<div style="text-align:center"><img src="../assets/3.png" style="width:80%; height:80%" /></div>

<div class="highlight"><pre><span></span><code><span class="n">ds</span> <span class="o">=</span> <span class="n">radtorch</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ImageDataset</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="s1">&#39;data/4CLASS/&#39;</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">WW</span><span class="o">=</span><span class="p">[</span><span class="mi">1500</span><span class="p">,</span> <span class="mi">350</span><span class="p">,</span> <span class="mi">80</span><span class="p">],</span> <span class="n">WL</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">600</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">40</span><span class="p">])</span>
<span class="n">ds</span><span class="o">.</span><span class="n">view_image</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
</code></pre></div>
<div style="text-align:center"><img src="../assets/4.png" style="width:80%; height:80%" /></div>

    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="radtorch.data.VolumeDataset" class="doc doc-heading">
        <code>
VolumeDataset            (<span title="torch.utils.data.dataset.Dataset">Dataset</span>)
        </code>



</h2>

    <div class="doc doc-contents first">

      <p>Dataset object for DICOM Volume. Creates dataset(s) and dataloader(s) ready for training using radtorch or pytorch directly.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>folder</code></td>
        <td><code>str</code></td>
        <td><p>Parent folder containing images. <code>radtorch.VolumeDataset</code> expects files to be arranged in the following structure:
        <div class="highlight"><pre><span></span><code>root/
    class_1/
            sequence_1/
                        image_1
                        image_2
                        ...
            sequence_2/
                        image_1
                        image_2
                        ...
    class_2/
            sequence_1/
                        image_1
                        image_2
                        ...
            sequence_2/
                        image_1
                        image_2
                        ...
    ...
</code></pre></div></p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>name</code></td>
        <td><code>str</code></td>
        <td><p>Name to be give to the dataset. If none provided, the current date and time will be used to created a generic dataset name. (default=None)</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>label_table</code></td>
        <td><code>str|dataframe</code></td>
        <td><p>The table containing data labels for your images. Expected table should contain at least 2 columns: image path column and a label column. Table can be string path to CSV or a pandas dataframe object.(default=None)</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>use_file</code></td>
        <td><code>bool</code></td>
        <td><p>True to use pre-generated/resampled volume files. To use Volume files:</p>
<ol>
<li>
<p>Volume files should be created using <code>radtorch.data.VolumeObject</code></p>
</li>
<li>
<p>Saved with extension <code>.pt</code>.</p>
</li>
<li>
<p>Placed in the sequence folder.</p>
</li>
</ol></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>extension</code></td>
        <td><code>str</code></td>
        <td><p>Type/Extension of images.</p></td>
        <td><code>&#39;dcm&#39;</code></td>
      </tr>
      <tr>
        <td><code>out_channels</code></td>
        <td><code>int</code></td>
        <td><p>Number of output channels.</p></td>
        <td><code>1</code></td>
      </tr>
      <tr>
        <td><code>WW</code></td>
        <td><code>int or list</code></td>
        <td><p>Window width for DICOM images. Single value if using 1 channel or list of 3 values for 3 channels. See <a href="https://radiopaedia.org/articles/windowing-ct">https://radiopaedia.org/articles/windowing-ct</a>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>WL</code></td>
        <td><code>int or list</code></td>
        <td><p>Window level for DICOM images. Single value if using 1 channel or list of 3 values for 3 channels. See <a href="https://radiopaedia.org/articles/windowing-ct">https://radiopaedia.org/articles/windowing-ct</a>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>path_col</code></td>
        <td><code>str</code></td>
        <td><p>Name of the column containing image path data in the label_table.</p></td>
        <td><code>&#39;path&#39;</code></td>
      </tr>
      <tr>
        <td><code>label_col</code></td>
        <td><code>str</code></td>
        <td><p>Name of the column containing label data in the label_table.</p></td>
        <td><code>&#39;label&#39;</code></td>
      </tr>
      <tr>
        <td><code>study_col</code></td>
        <td><code>str</code></td>
        <td><p>Name of the column containing study id in label_table.</p></td>
        <td><code>&#39;study_id&#39;</code></td>
      </tr>
      <tr>
        <td><code>transforms</code></td>
        <td><code>dict</code></td>
        <td><p>Dictionary of Albumentations transformations in the form of {'train': .. , 'valid': .. , 'test': .. }. See https://albumentations.ai/docs/getting_started/image_augmentation/. NOTE: If using already resampled/created volume files, transformation should be applied during volume creation not dataset i.e. Transforms specified here have no effect during training.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>random_state</code></td>
        <td><code>int</code></td>
        <td><p>Random seed.</p></td>
        <td><code>100</code></td>
      </tr>
      <tr>
        <td><code>sample</code></td>
        <td><code>float</code></td>
        <td><p>Sample or percent of the overall data to be used.</p></td>
        <td><code>1.0</code></td>
      </tr>
      <tr>
        <td><code>split</code></td>
        <td><code>dict</code></td>
        <td><p>dictionary defining how data will be split for training/validation/testing. Follows the sturcture {'valid': float, 'test': float} or {'valid':'float'} in case no testing subset is needed. The percent of the training subset is infered automatically.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>normalize</code></td>
        <td><code>bool</code></td>
        <td><p>True to normalize image data between 0 and 1.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>batch_size</code></td>
        <td><code>int</code></td>
        <td><p>Dataloader batch size.</p></td>
        <td><code>16</code></td>
      </tr>
      <tr>
        <td><code>shuffle</code></td>
        <td><code>bool</code></td>
        <td><p>True to shuffle images during training.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>weighted_sampler</code></td>
        <td><code>bool</code></td>
        <td><p>True to use a weighted sampler for unbalanced datasets. See https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>num_workers</code></td>
        <td><code>int</code></td>
        <td><p>Dataloader CPU workers.</p></td>
        <td><code>0</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Attributes:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>classes</code></td>
        <td><code>list</code></td>
        <td><p>List of generated classes/labels.</p></td>
      </tr>
      <tr>
        <td><code>class_to_idx</code></td>
        <td><code>dict</code></td>
        <td><p>Dictionary of generated classes/labels and corresponding class/label id.</p></td>
      </tr>
      <tr>
        <td><code>idx_train</code></td>
        <td><code>list</code></td>
        <td><p>List of index values of images/instances used for training subset. These refer to index of <code>ImageDataset.table</code>.</p></td>
      </tr>
      <tr>
        <td><code>idx_valid</code></td>
        <td><code>list</code></td>
        <td><p>List of index values of images/instances used for validation subset. These refer to index of <code>ImageDataset.table</code>.</p></td>
      </tr>
      <tr>
        <td><code>idx_test</code></td>
        <td><code>list</code></td>
        <td><p>List of index values of images/instances used for testing subset. These refer to index of <code>ImageDataset.table</code>.</p></td>
      </tr>
      <tr>
        <td><code>table</code></td>
        <td><code>pandas dataframe</code></td>
        <td><p>Table of images , paths and their labels.</p></td>
      </tr>
      <tr>
        <td><code>table_train</code></td>
        <td><code>pandas dataframe</code></td>
        <td><p>Table of images used for training. Subset of <code>ImageDataset.table</code>.</p></td>
      </tr>
      <tr>
        <td><code>table_valid</code></td>
        <td><code>pandas dataframe</code></td>
        <td><p>Table of images used for validation. Subset of <code>ImageDataset.table</code>.</p></td>
      </tr>
      <tr>
        <td><code>table_test</code></td>
        <td><code>pandas dataframe</code></td>
        <td><p>Table of images used for testing. Subset of <code>ImageDataset.table</code>.</p></td>
      </tr>
      <tr>
        <td><code>tables</code></td>
        <td><code>dict</code></td>
        <td><p>Dictionary of all generated tables in the form of: {'train': table, 'valid':table, 'test':table}.</p></td>
      </tr>
      <tr>
        <td><code>dataset_train</code></td>
        <td><code>pytorch dataset object</code></td>
        <td><p>Training <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset">pytorch Dataset</a></p></td>
      </tr>
      <tr>
        <td><code>dataset_valid</code></td>
        <td><code>pytorch dataset object</code></td>
        <td><p>Validation <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset">pytorch Dataset</a></p></td>
      </tr>
      <tr>
        <td><code>dataset_test</code></td>
        <td><code>pytorch dataset object</code></td>
        <td><p>Testing <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset">pytorch Dataset</a></p></td>
      </tr>
      <tr>
        <td><code>datasets</code></td>
        <td><code>dict</code></td>
        <td><p>Dictionary of all generated Datasets in the form of: {'train': Dataset, 'valid':Dataset, 'test':Dataset}.</p></td>
      </tr>
      <tr>
        <td><code>dataloader_train</code></td>
        <td><code>pytorch dataloader object</code></td>
        <td><p>Training <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">pytorch DataLoader</a></p></td>
      </tr>
      <tr>
        <td><code>dataloader_valid</code></td>
        <td><code>pytorch dataloader object</code></td>
        <td><p>Validation <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">pytorch DataLoader</a></p></td>
      </tr>
      <tr>
        <td><code>dataloader_test</code></td>
        <td><code>pytorch dataloader object</code></td>
        <td><p>Testing <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">pytorch DataLoader</a></p></td>
      </tr>
      <tr>
        <td><code>dataloaders</code></td>
        <td><code>dict</code></td>
        <td><p>Dictionary of all generated Dataloaders in the form of: {'train': Dataloader, 'valid':Dataloader, 'test':Dataloader}.</p></td>
      </tr>
      <tr>
        <td><code>class_weights</code></td>
        <td><code>tensor</code></td>
        <td><p>Values of class weights, for imbalanced datasets, to be used to weight loss functions. See <a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss">https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss</a>.</p></td>
      </tr>
      <tr>
        <td><code>sampler_weights</code></td>
        <td><code>tensor</code></td>
        <td><p>Values of vlass weights, for imbalanced datasets, to be used to sample from the dataset using Pytroch WeightedRandomSampler. Affects only training dataset not validation or testing. See <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler">https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler</a></p></td>
      </tr>
  </tbody>
</table>
<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">radtorch</span>
<span class="kn">import</span> <span class="nn">albumentations</span> <span class="k">as</span> <span class="nn">A</span>

<span class="c1"># Specify image transformations</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">A</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">)])</span>

<span class="c1"># Create dataset object</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">radtorch</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">VolumeDataset</span><span class="p">(</span>
                                <span class="n">folder</span><span class="o">=</span><span class="s1">&#39;data/PROTOTYPE/DIRECTORY/&#39;</span><span class="p">,</span>
                                <span class="n">split</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;valid&#39;</span><span class="p">:</span><span class="mf">0.3</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span><span class="mf">0.3</span><span class="p">},</span>
                                <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">transforms</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span><span class="n">T</span><span class="p">,</span><span class="s1">&#39;valid&#39;</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span><span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="n">T</span><span class="p">},</span>
                                 <span class="p">)</span>

<span class="n">ds</span><span class="o">.</span><span class="n">data_stat</span><span class="p">()</span>
</code></pre></div>
<div style="text-align:center"><img src="../assets/7.png" style="width:50%; height:50%" /></div>

<div class="highlight"><pre><span></span><code><span class="n">ds</span><span class="o">.</span><span class="n">table</span>
</code></pre></div>
<div style="text-align:center"><img src="../assets/8.png" style="width:50%; height:50%" /></div>




  <div class="doc doc-children">







<h3 id="radtorch.data.VolumeDataset-methods">Methods</h3>

  <div class="doc doc-object doc-method">



<h4 id="radtorch.data.VolumeDataset.data_stat" class="doc doc-heading">
<code class="highlight language-python"><span class="n">data_stat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>Displays distribution of classes across subsets as table or plot.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>plot</code></td>
        <td><code>bool</code></td>
        <td><p>True, display data as figure. False, display data as table.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>figsize</code></td>
        <td><code>tuple</code></td>
        <td><p>size of the displayed figure.</p></td>
        <td><code>(8, 6)</code></td>
      </tr>
      <tr>
        <td><code>cmap</code></td>
        <td><code>string</code></td>
        <td><p>Name of Matplotlib color map to be used. See <a href="https://matplotlib.org/stable/tutorials/colors/colormaps.html">Matplotlib colormaps</a></p></td>
        <td><code>&#39;viridis&#39;</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>pandas dataframe</code></td>
      <td><p>if plot=False</p></td>
    </tr>
  </tbody>
</table>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 id="radtorch.data.VolumeDataset.view_study" class="doc doc-heading">
<code class="highlight language-python"><span class="n">view_study</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">id</span><span class="p">,</span> <span class="n">plane</span><span class="o">=</span><span class="s1">&#39;axial&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="n">cols</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">rows</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>Show sample images from a study.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This works only with single channel images. Multiple channels are not supported yet here.</p>
</div>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>id</code></td>
        <td><code>int</code></td>
        <td><p>Target study id in <code>dataset.table</code> (row index).</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>plane</code></td>
        <td><code>str</code></td>
        <td><p>Anatomical plane to display the images in. Options: 'axial', 'coronal' or 'sagittal'.</p></td>
        <td><code>&#39;axial&#39;</code></td>
      </tr>
      <tr>
        <td><code>figsize</code></td>
        <td><code>tuple</code></td>
        <td><p>Size of the displayed figure.</p></td>
        <td><code>(15, 15)</code></td>
      </tr>
      <tr>
        <td><code>cols</code></td>
        <td><code>int</code></td>
        <td><p>Number of columns.</p></td>
        <td><code>5</code></td>
      </tr>
      <tr>
        <td><code>rows</code></td>
        <td><code>int</code></td>
        <td><p>Number of rows.</p></td>
        <td><code>5</code></td>
      </tr>
      <tr>
        <td><code>start</code></td>
        <td><code>int</code></td>
        <td><p>id of the first image to display.</p></td>
        <td><code>0</code></td>
      </tr>
      <tr>
        <td><code>end</code></td>
        <td><code>int</code></td>
        <td><p>id of the last image to display.</p></td>
        <td><code>-1</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>figure</code></td>
      <td><p>figure containing images from study.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Examples:</strong></p>
    <p><div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">radtorch</span>
<span class="kn">import</span> <span class="nn">albumentations</span> <span class="k">as</span> <span class="nn">A</span>

<span class="c1"># Specify image transformations</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">A</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">)])</span>

<span class="c1"># Create dataset object</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">radtorch</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">VolumeDataset</span><span class="p">(</span>
                                <span class="n">folder</span><span class="o">=</span><span class="s1">&#39;data/PROTOTYPE/DIRECTORY/&#39;</span><span class="p">,</span>
                                <span class="n">split</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;valid&#39;</span><span class="p">:</span><span class="mf">0.3</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span><span class="mf">0.3</span><span class="p">},</span>
                                <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">transforms</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span><span class="n">T</span><span class="p">,</span><span class="s1">&#39;valid&#39;</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span><span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="n">T</span><span class="p">},</span>
                     <span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">ds</span><span class="o">.</span><span class="n">view_study</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">plane</span><span class="o">=</span><span class="s1">&#39;axial&#39;</span><span class="p">)</span>
</code></pre></div></p>
<div style="text-align:center"><img src="../assets/9.png" style="width:50%; height:50%" /></div>

<div class="highlight"><pre><span></span><code><span class="n">ds</span><span class="o">.</span><span class="n">view_study</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">plane</span><span class="o">=</span><span class="s1">&#39;coronal&#39;</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</code></pre></div>
<div style="text-align:center"><img src="../assets/10.png" style="width:50%; height:50%" /></div>

    </div>

  </div>





  </div>

    </div>

  </div>
                
              
              
                


              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Back to top
          </a>
        
      </main>
      
        
<footer class="md-footer">
  <!-- 
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../start/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Getting Started" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Getting Started
            </div>
          </div>
        </a>
      
      
        
        <a href="../model/" class="md-footer__link md-footer__link--next" aria-label="Next: Model &lt;small&gt;radtorch.model&lt;/small&gt;" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Model <small>radtorch.model</small>
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
   -->
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        <!-- Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a> -->
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.sections", "toc.integrate", "navigation.top", "navigation.tabs"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.709b4209.min.js", "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.febc23d1.min.js"></script>
      
        <script src="https://unpkg.com/mermaid@8.8.0/dist/mermaid.min.js"></script>
      
    
  </body>
</html>